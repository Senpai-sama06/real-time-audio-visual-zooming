{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512fc02b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3704282796.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# IMPORT EVAL FUNCTIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# ------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m from eval import (\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mload_and_align_signals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcalculate_osnr_and_osir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eval'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "bulk_compare_gpu.py\n",
    "\n",
    "End-to-end bulk comparison script:\n",
    "1. Generate acoustic world (world.py logic)\n",
    "2. Unified noise covariance estimation\n",
    "3. MVDR + SMVB beamforming (GPU accelerated)\n",
    "4. Evaluation using eval.py metrics (CPU)\n",
    "5. Log results to CSV\n",
    "\n",
    "Authoritative experiment loop.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# ------------------------\n",
    "# USER CONFIG\n",
    "# ------------------------\n",
    "N_SAMPLES = 100\n",
    "SAVE_DIR = \"sample\"\n",
    "CSV_PATH = \"bulk_results.csv\"\n",
    "\n",
    "FS = 16000\n",
    "N_FFT = 256\n",
    "N_HOP = 128\n",
    "D = 0.08\n",
    "C = 343.0\n",
    "ANGLE_TARGET = 90.0\n",
    "SIGMA = 1e-3\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------------\n",
    "# IMPORT EVAL FUNCTIONS\n",
    "# ------------------------\n",
    "from eval import (\n",
    "    load_and_align_signals,\n",
    "    calculate_osnr_and_osir,\n",
    "    calculate_pesq_metric\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# STEERING VECTOR (GPU)\n",
    "# ============================================================\n",
    "def steering_vector(f_hz):\n",
    "    theta = torch.deg2rad(torch.tensor(ANGLE_TARGET, device=DEVICE))\n",
    "    omega = 2 * np.pi * f_hz\n",
    "\n",
    "    tau1 = (D / 2) * torch.cos(theta) / C\n",
    "    tau2 = (D / 2) * torch.cos(theta - np.pi) / C\n",
    "\n",
    "    v = torch.stack([\n",
    "        torch.exp(-1j * omega * tau1),\n",
    "        torch.exp(-1j * omega * tau2)\n",
    "    ], dim=0).reshape(2, 1)\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GPU PIPELINE\n",
    "# ============================================================\n",
    "def run_beamformers_gpu():\n",
    "    # ---------- Load audio ----------\n",
    "    y_mix, _ = sf.read(f\"{SAVE_DIR}/mixture.wav\", dtype=\"float32\")\n",
    "    s_t, _ = sf.read(f\"{SAVE_DIR}/target.wav\", dtype=\"float32\")\n",
    "    s_i, _ = sf.read(f\"{SAVE_DIR}/interference.wav\", dtype=\"float32\")\n",
    "    s_n, _ = sf.read(f\"{SAVE_DIR}/noise.wav\", dtype=\"float32\")\n",
    "\n",
    "    # Mono references\n",
    "    s_t = s_t[:, 0] if s_t.ndim > 1 else s_t\n",
    "    s_i = s_i[:, 0] if s_i.ndim > 1 else s_i\n",
    "    s_n = s_n[:, 0] if s_n.ndim > 1 else s_n\n",
    "\n",
    "    # To torch\n",
    "    Y = torch.tensor(y_mix.T, device=DEVICE)\n",
    "    s_t = torch.tensor(s_t, device=DEVICE)\n",
    "    s_i = torch.tensor(s_i, device=DEVICE)\n",
    "    s_n = torch.tensor(s_n, device=DEVICE)\n",
    "\n",
    "    # ---------- STFT ----------\n",
    "    Y_stft = torch.stft(Y, N_FFT, N_HOP, return_complex=True)\n",
    "    S_t = torch.stft(s_t, N_FFT, N_HOP, return_complex=True)\n",
    "    S_i = torch.stft(s_i, N_FFT, N_HOP, return_complex=True)\n",
    "    S_n = torch.stft(s_n, N_FFT, N_HOP, return_complex=True)\n",
    "\n",
    "    # ---------- Oracle mask ----------\n",
    "    mag_t2 = torch.abs(S_t) ** 2\n",
    "    mag_i2 = torch.abs(S_i) ** 2\n",
    "    mag_n2 = torch.abs(S_n) ** 2\n",
    "\n",
    "    mask_t = mag_t2 / (mag_t2 + mag_i2 + mag_n2 + 1e-10)\n",
    "    mask_in = 1.0 - mask_t\n",
    "\n",
    "    # ---------- Covariance ----------\n",
    "    n_freq = Y_stft.shape[1]\n",
    "    R_in = torch.zeros((n_freq, 2, 2), dtype=torch.complex64, device=DEVICE)\n",
    "\n",
    "    for f in range(n_freq):\n",
    "        w = torch.sqrt(mask_in[f])\n",
    "        Yf = Y_stft[:, f, :]\n",
    "        Yw = Yf * w\n",
    "        R_in[f] = (Yw @ Yw.conj().T) / (torch.sum(w**2) + 1e-8)\n",
    "\n",
    "    # ---------- Beamforming ----------\n",
    "    S_mvdr = torch.zeros_like(S_t)\n",
    "    S_smvb = torch.zeros_like(S_t)\n",
    "\n",
    "    for f in range(n_freq):\n",
    "        f_hz = f * FS / N_FFT\n",
    "        if f_hz < 100:\n",
    "            S_mvdr[f] = Y_stft[0, f]\n",
    "            S_smvb[f] = Y_stft[0, f]\n",
    "            continue\n",
    "\n",
    "        R = R_in[f] + SIGMA * torch.eye(2, device=DEVICE)\n",
    "        d = steering_vector(f_hz)\n",
    "\n",
    "        # MVDR\n",
    "        w_mvdr = torch.linalg.solve(R, d)\n",
    "        w_mvdr /= (d.conj().T @ w_mvdr + 1e-10)\n",
    "        S_mvdr[f] = (w_mvdr.conj().T @ Y_stft[:, f]).squeeze()\n",
    "\n",
    "        # SMVB\n",
    "        eigvals, eigvecs = torch.linalg.eigh(R_in[f])\n",
    "        v_int = eigvecs[:, -1].reshape(2, 1)\n",
    "        v_tgt = d\n",
    "        Cmat = torch.cat([v_tgt, v_int], dim=1)\n",
    "\n",
    "        if torch.linalg.cond(Cmat) < 10:\n",
    "            w_smvb = torch.linalg.solve(Cmat.conj().T,\n",
    "                                        torch.tensor([[1.0], [0.0]], device=DEVICE))\n",
    "        else:\n",
    "            w_smvb = v_tgt / 2.0\n",
    "\n",
    "        S_smvb[f] = (w_smvb.conj().T @ Y_stft[:, f]).squeeze()\n",
    "\n",
    "    # ---------- Post-filter + ISTFT ----------\n",
    "    s_mvdr = torch.istft(S_mvdr * mask_t, N_FFT, N_HOP).cpu().numpy()\n",
    "    s_smvb = torch.istft(S_smvb * mask_t, N_FFT, N_HOP).cpu().numpy()\n",
    "\n",
    "    s_mvdr /= np.max(np.abs(s_mvdr)) + 1e-10\n",
    "    s_smvb /= np.max(np.abs(s_smvb)) + 1e-10\n",
    "\n",
    "    sf.write(f\"{SAVE_DIR}/output_unified_mvdr.wav\", s_mvdr.astype(np.float32), FS)\n",
    "    sf.write(f\"{SAVE_DIR}/output_unified_smvb.wav\", s_smvb.astype(np.float32), FS)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN BULK LOOP\n",
    "# ============================================================\n",
    "def main():\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"sample_id\", \"mvdr_sir\", \"smvb_sir\",\n",
    "                          \"mvdr_pesq\", \"smvb_pesq\"])\n",
    "\n",
    "        for i in range(N_SAMPLES):\n",
    "            print(f\"\\n=== Sample {i} ===\")\n",
    "\n",
    "            # 1. World generation\n",
    "            subprocess.run([\n",
    "                \"python\", \"world.py\",\n",
    "                \"--no-reverb\",\n",
    "                \"--dataset\", \"ljspeech\",\n",
    "                \"--n\", \"1\"\n",
    "            ], check=True)\n",
    "\n",
    "            # 2. GPU processing\n",
    "            run_beamformers_gpu()\n",
    "\n",
    "            # 3. Evaluation (MVDR)\n",
    "            s_est, s_tgt, s_int, _, _ = load_and_align_signals(\n",
    "                f\"{SAVE_DIR}/output_unified_mvdr.wav\", SAVE_DIR)\n",
    "            _, mvdr_sir, _, _, _ = calculate_osnr_and_osir(s_est, s_tgt, s_int)\n",
    "            mvdr_pesq, _ = calculate_pesq_metric(s_tgt, s_est, FS)\n",
    "\n",
    "            # 4. Evaluation (SMVB)\n",
    "            s_est, s_tgt, s_int, _, _ = load_and_align_signals(\n",
    "                f\"{SAVE_DIR}/output_unified_smvb.wav\", SAVE_DIR)\n",
    "            _, smvb_sir, _, _, _ = calculate_osnr_and_osir(s_est, s_tgt, s_int)\n",
    "            smvb_pesq, _ = calculate_pesq_metric(s_tgt, s_est, FS)\n",
    "\n",
    "            # 5. Log\n",
    "            writer.writerow([i, mvdr_sir, smvb_sir, mvdr_pesq, smvb_pesq])\n",
    "            print(f\"Logged sample {i}\")\n",
    "\n",
    "    print(\"\\nBulk comparison complete.\")\n",
    "    print(f\"Results saved to {CSV_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485bf1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile torch torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db8b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
