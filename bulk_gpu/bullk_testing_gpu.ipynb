{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721d1fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: pystoi in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
      "Collecting pesq\n",
      "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pystoi) (1.16.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Building wheels for collected packages: pesq\n",
      "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pesq: filename=pesq-0.0.4-cp312-cp312-linux_x86_64.whl size=284117 sha256=bd9d460dbdfbd2077993a1d2f5c5b18ea0838c2ed8d414a43d2bb79e060da845\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/d4/a4/9cf3512534cd47ce4a036d1593ee4013f2bf7509e631a147a3\n",
      "Successfully built pesq\n",
      "Installing collected packages: pesq\n",
      "Successfully installed pesq-0.0.4\n"
     ]
    }
   ],
   "source": [
    "%pip install soundfile torch torchaudio pystoi pesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b00bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SP CUP 2026: Official Metrics Scoreboard ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import sys\n",
    "import datetime \n",
    "from typing import Union, Tuple\n",
    "\n",
    "# External Libraries required for Objective Metrics\n",
    "try:\n",
    "    from pystoi import stoi\n",
    "    from pesq import pesq\n",
    "except ImportError:\n",
    "    print(\"FATAL ERROR: Required packages (pystoi/pesq) not found. Please install them.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# --- PESQ EVALUATOR CLASS ---\n",
    "\n",
    "class PESQEvaluator:\n",
    "\n",
    "    \"\"\"\n",
    "    An object-oriented class for calculating the Perceptual Evaluation of Speech\n",
    "    Quality (PESQ) score between a reference and a degraded audio signal.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ref_audio: np.ndarray, deg_audio: np.ndarray, fs: int):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with audio data.\n",
    "        \"\"\"\n",
    "        self.fs = fs\n",
    "        self.ref_audio = ref_audio\n",
    "        self.deg_audio = deg_audio\n",
    "\n",
    "    def calculate_pesq(self, mode: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the PESQ score for a given mode.\n",
    "        \"\"\"\n",
    "        if self.fs is None or self.ref_audio is None or self.deg_audio is None:\n",
    "            raise RuntimeError(\"Audio data was not loaded correctly.\")\n",
    "\n",
    "        # Allow 16000 Hz for Narrow-Band, as the pesq library handles downsampling.\n",
    "        if mode == 'nb' and self.fs not in [8000, 16000]:\n",
    "            raise ValueError(\n",
    "                f\"Narrow-Band PESQ requires 8000 Hz or 16000 Hz input, but audio is {self.fs} Hz.\"\n",
    "            )\n",
    "        # Wide-Band requires exactly 16000 Hz.\n",
    "        elif mode == 'wb' and self.fs != 16000:\n",
    "            raise ValueError(\n",
    "                f\"Wide-Band PESQ requires 16000 Hz, but audio is {self.fs} Hz.\"\n",
    "            )\n",
    "        elif mode not in ['nb', 'wb']:\n",
    "            raise ValueError(f\"Invalid mode: {mode}. Must be 'nb' or 'wb'.\")\n",
    "\n",
    "        score = pesq(self.fs, self.ref_audio, self.deg_audio, mode)\n",
    "        return score\n",
    "\n",
    "    def evaluate(self) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Runs both Narrow-Band and Wide-Band evaluation, if supported by the fs.\n",
    "\n",
    "        Returns:\n",
    "            A tuple (nb_pesq_score, wb_pesq_score). Scores will be 0.0 if not supported.\n",
    "        \"\"\"\n",
    "        nb_score = 0.0\n",
    "        wb_score = 0.0\n",
    "\n",
    "        if self.fs == 16000:\n",
    "            nb_score = self.calculate_pesq('nb')\n",
    "            wb_score = self.calculate_pesq('wb')\n",
    "        elif self.fs == 8000:\n",
    "            nb_score = self.calculate_pesq('nb')\n",
    "            \n",
    "        return nb_score, wb_score\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FS = 16000 \n",
    "HISTORY_FILE = \"evaluation_history.txt\"\n",
    "\n",
    "\n",
    "def load_and_align_signals(output_file_full_path, output_path):\n",
    "    \"\"\"Loads all required files and aligns them to the minimum length.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load the estimated signal\n",
    "        s_est, _ = sf.read(output_file_full_path, dtype='float32')\n",
    "        \n",
    "        # Load reference files using the output_path\n",
    "        s_tgt_ref, _ = sf.read(os.path.join(output_path, \"target.wav\"), dtype='float32')\n",
    "        s_int_ref, _ = sf.read(os.path.join(output_path, \"interference.wav\"), dtype='float32')\n",
    "        s_mix, _ = sf.read(os.path.join(output_path, \"mixture.wav\"), dtype='float32')\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        missing_file = str(e).split(\"'\")[1]\n",
    "        print(f\"Error loading files: Missing file '{missing_file}'. Ensure all files exist in the specified path.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # Handle multi-channel (keep only first channel)\n",
    "    if len(s_mix.shape) > 1: s_mix = s_mix[:, 0]\n",
    "    if len(s_est.shape) > 1: s_est = s_est[:, 0]\n",
    "    if len(s_tgt_ref.shape) > 1: s_tgt_ref = s_tgt_ref[:, 0]\n",
    "    if len(s_int_ref.shape) > 1: s_int_ref = s_int_ref[:, 0]\n",
    "\n",
    "    # Align to minimum length\n",
    "    min_len = min(len(s_est), len(s_tgt_ref), len(s_int_ref), len(s_mix))\n",
    "    \n",
    "    # Cast to float64 for PESQ compatibility\n",
    "    s_est = s_est[:min_len].astype(np.float64)\n",
    "    s_tgt_ref = s_tgt_ref[:min_len].astype(np.float64)\n",
    "    s_int_ref = s_int_ref[:min_len].astype(np.float64)\n",
    "    s_mix = s_mix[:min_len].astype(np.float64)\n",
    "    \n",
    "    return s_est, s_tgt_ref, s_int_ref, s_mix, min_len\n",
    "\n",
    "def calculate_osnr_and_osir(output_signal, target_ref, interf_ref):\n",
    "    \"\"\"Calculates OSINR and OSIR using projection method.\"\"\"\n",
    "    \n",
    "    floor_norm = 1e-10\n",
    "    \n",
    "    # 1. Normalize all inputs to unit energy\n",
    "    target_ref = target_ref / (np.linalg.norm(target_ref) + floor_norm)\n",
    "    interf_ref = interf_ref / (np.linalg.norm(interf_ref) + floor_norm)\n",
    "\n",
    "    # 2. Projection Method\n",
    "    alpha = np.dot(output_signal, target_ref)\n",
    "    e_target = alpha * target_ref\n",
    "    \n",
    "    beta = np.dot(output_signal, interf_ref)\n",
    "    e_interf = beta * interf_ref\n",
    "    \n",
    "    # 3. Calculate Residual Error (Artifacts/Noise)\n",
    "    e_artif_noise = output_signal - e_target - e_interf\n",
    "    \n",
    "    # 4. Calculate Powers\n",
    "    P_target = np.sum(e_target**2)\n",
    "    P_interf = np.sum(e_interf**2)\n",
    "    P_noise  = np.sum(e_artif_noise**2)\n",
    "    \n",
    "    floor_log = 1e-10           \n",
    "    \n",
    "    # OSINR = 10 * log10( P_target / (P_interf + P_noise) )\n",
    "    OSINR = 10 * np.log10( P_target / (P_interf + P_noise + floor_log) )\n",
    "    \n",
    "    # OSIR = 10 * log10( P_target / P_interf )\n",
    "    OSIR = 10 * np.log10( P_target / (P_interf + floor_log) )\n",
    "    \n",
    "    return OSINR, OSIR, P_target, P_interf, P_noise\n",
    "\n",
    "def calculate_pesq_metric(target_ref, processed_signal, fs):\n",
    "    \"\"\"Calculates PESQ Wide-Band and Narrow-Band scores.\"\"\"\n",
    "    try:\n",
    "        evaluator = PESQEvaluator(target_ref, processed_signal, fs)\n",
    "        nb_score, wb_score = evaluator.evaluate()\n",
    "        return wb_score, nb_score\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: PESQ calculation failed: {e}\")\n",
    "        return 0.0, 0.0 # Return 0.0 if calculation fails\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"--- SP CUP 2026: Official Metrics Scoreboard ---\")\n",
    "    \n",
    "    # # --- HARDCODED PATH DEFINITIONS (Modify these for your setup) ---\n",
    "    # # OUTPUT_PATH = \"/home/cse-sdpl/paarth/real-time-audio-visual-zooming/experiments/masked_mvdr_exp/samples\"\n",
    "    # OUTPUT_PATH = \"/home/rpzrm/global/projects/real-time-audio-visual-zooming/experiments/reverb/sample/\"\n",
    "    # # BASE_FILENAME = \"enh_mix\"\n",
    "    # # BASE_FILENAME = \"duet_target_90deg\"\n",
    "    # # BASE_FILENAME = \"output_unified_mvdr\"\n",
    "    # BASE_FILENAME = \"output_unified_smvb\"\n",
    "    \n",
    "    # # Construct the full path for the estimated signal\n",
    "    # output_file_full_path = os.path.join(OUTPUT_PATH, f\"{BASE_FILENAME}.wav\")\n",
    "    \n",
    "    # # Load all signals (s_est = estimated, s_tgt = target, s_int = interference, s_mix = mixture)\n",
    "    # s_est, s_tgt, s_int, s_mix, L = load_and_align_signals(output_file_full_path, OUTPUT_PATH)\n",
    "    \n",
    "    # if L is None: return\n",
    "\n",
    "    # # --- 1. Calculate Metrics ---\n",
    "    \n",
    "    # # Calculate baseline metrics for comparison (s_mix)\n",
    "    # OSINR_b, OSIR_b, _, _, _ = calculate_osnr_and_osir(s_mix, s_tgt, s_int)\n",
    "\n",
    "    # # Calculate solution metrics (s_est)\n",
    "    # OSINR_s, OSIR_s, P_target_s, P_interf_s, P_noise_s = calculate_osnr_and_osir(s_est, s_tgt, s_int)\n",
    "    \n",
    "    # # STOI\n",
    "    # STOI_score = stoi(s_tgt, s_est, FS)\n",
    "    \n",
    "    # # PESQ\n",
    "    # PESQ_WB_score, PESQ_NB_score = calculate_pesq_metric(s_tgt, s_est, FS)\n",
    "    \n",
    "    # # --- 2. FORMAT OUTPUT ---\n",
    "    \n",
    "    # current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # SIR_IMPROVEMENT = OSIR_s - OSIR_b\n",
    "    \n",
    "    # report_lines = [\n",
    "    #     f\"========================================================\",\n",
    "    #     f\"EVALUATION RUNTIME: {current_time}\",\n",
    "    #     f\"FILE TESTED:        {os.path.basename(output_file_full_path)}\",\n",
    "    #     f\"--------------------------------------------------------\",\n",
    "    #     f\"BASELINE (Raw Mix):\",\n",
    "    #     f\"  Input SIR: {OSIR_b:.2f} dB\",\n",
    "    #     f\"  Input OSINR: {OSINR_b:.2f} dB\",\n",
    "    #     f\"--------------------------------------------------------\",\n",
    "    #     f\"PROCESSED SIGNAL:\",\n",
    "    #     f\"  Output OSIR: {OSIR_s:.2f} dB\",\n",
    "    #     f\"  Output OSINR: {OSINR_s:.2f} dB\",\n",
    "    #     f\"  STOI Score:  {STOI_score:.4f}\",\n",
    "    #     f\"  PESQ-WB Score: {PESQ_WB_score:.4f}\",\n",
    "    #     f\"  PESQ-NB Score: {PESQ_NB_score:.4f}\",\n",
    "    #     f\"--------------------------------------------------------\",\n",
    "    #     f\"TOTAL SIR IMPROVEMENT: +{SIR_IMPROVEMENT:.2f} dB\",\n",
    "    #     f\"========================================================\\n\"\n",
    "    # ]\n",
    "\n",
    "    # report = \"\\n\".join(report_lines)\n",
    "    \n",
    "    # # --- 3. APPEND TO HISTORY FILE ---\n",
    "    # try:\n",
    "    #     with open(os.path.join(OUTPUT_PATH, HISTORY_FILE), 'a') as f:\n",
    "    #         f.write(report)\n",
    "    #     print(\"\\nReport successfully generated:\")\n",
    "    #     print(report)\n",
    "    #     print(f\"Results appended to {os.path.join(OUTPUT_PATH, HISTORY_FILE)}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"\\nFATAL ERROR: Could not write to history file. {e}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "512fc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 0 ===\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python', 'world.py', '--no-reverb', '--dataset', 'ljspeech', '--n', '1']' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4284908894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-4284908894.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# 1. World generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             subprocess.run([\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"world.py\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;34m\"--no-reverb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['python', 'world.py', '--no-reverb', '--dataset', 'ljspeech', '--n', '1']' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "bulk_compare_gpu.py\n",
    "\n",
    "End-to-end bulk comparison script:\n",
    "1. Generate acoustic world (world.py logic)\n",
    "2. Unified noise covariance estimation\n",
    "3. MVDR + SMVB beamforming (GPU accelerated)\n",
    "4. Evaluation using eval.py metrics (CPU)\n",
    "5. Log results to CSV\n",
    "\n",
    "Authoritative experiment loop.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# ------------------------\n",
    "# USER CONFIG\n",
    "# ------------------------\n",
    "N_SAMPLES = 100\n",
    "SAVE_DIR = \"sample\"\n",
    "CSV_PATH = \"bulk_results.csv\"\n",
    "\n",
    "FS = 16000\n",
    "N_FFT = 256\n",
    "N_HOP = 128\n",
    "D = 0.08\n",
    "C = 343.0\n",
    "ANGLE_TARGET = 90.0\n",
    "SIGMA = 1e-3\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------------\n",
    "# IMPORT EVAL FUNCTIONS\n",
    "# ------------------------\n",
    "# from eval import (\n",
    "#     load_and_align_signals,\n",
    "#     calculate_osnr_and_osir,\n",
    "#     calculate_pesq_metric\n",
    "# )\n",
    "\n",
    "# ============================================================\n",
    "# STEERING VECTOR (GPU)\n",
    "# ============================================================\n",
    "def steering_vector(f_hz):\n",
    "    theta = torch.deg2rad(torch.tensor(ANGLE_TARGET, device=DEVICE))\n",
    "    omega = 2 * np.pi * f_hz\n",
    "\n",
    "    tau1 = (D / 2) * torch.cos(theta) / C\n",
    "    tau2 = (D / 2) * torch.cos(theta - np.pi) / C\n",
    "\n",
    "    v = torch.stack([\n",
    "        torch.exp(-1j * omega * tau1),\n",
    "        torch.exp(-1j * omega * tau2)\n",
    "    ], dim=0).reshape(2, 1)\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GPU PIPELINE\n",
    "# ============================================================\n",
    "def run_beamformers_gpu():\n",
    "    # ---------- Load audio ----------\n",
    "    y_mix, _ = sf.read(f\"{SAVE_DIR}/mixture.wav\", dtype=\"float32\")\n",
    "    s_t, _ = sf.read(f\"{SAVE_DIR}/target.wav\", dtype=\"float32\")\n",
    "    s_i, _ = sf.read(f\"{SAVE_DIR}/interference.wav\", dtype=\"float32\")\n",
    "    s_n, _ = sf.read(f\"{SAVE_DIR}/noise.wav\", dtype=\"float32\")\n",
    "\n",
    "    # Mono references\n",
    "    s_t = s_t[:, 0] if s_t.ndim > 1 else s_t\n",
    "    s_i = s_i[:, 0] if s_i.ndim > 1 else s_i\n",
    "    s_n = s_n[:, 0] if s_n.ndim > 1 else s_n\n",
    "\n",
    "    # To torch\n",
    "    Y = torch.tensor(y_mix.T, device=DEVICE)\n",
    "    s_t = torch.tensor(s_t, device=DEVICE)\n",
    "    s_i = torch.tensor(s_i, device=DEVICE)\n",
    "    s_n = torch.tensor(s_n, device=DEVICE)\n",
    "\n",
    "    # ---------- STFT ----------\n",
    "    Y_stft = torch.stft(Y, N_FFT, N_HOP, return_complex=True)\n",
    "    S_t = torch.stft(s_t, N_FFT, N_HOP, return_complex=True)\n",
    "    S_i = torch.stft(s_i, N_FFT, N_HOP, return_complex=True)\n",
    "    S_n = torch.stft(s_n, N_FFT, N_HOP, return_complex=True)\n",
    "\n",
    "    # ---------- Oracle mask ----------\n",
    "    mag_t2 = torch.abs(S_t) ** 2\n",
    "    mag_i2 = torch.abs(S_i) ** 2\n",
    "    mag_n2 = torch.abs(S_n) ** 2\n",
    "\n",
    "    mask_t = mag_t2 / (mag_t2 + mag_i2 + mag_n2 + 1e-10)\n",
    "    mask_in = 1.0 - mask_t\n",
    "\n",
    "    # ---------- Covariance ----------\n",
    "    n_freq = Y_stft.shape[1]\n",
    "    R_in = torch.zeros((n_freq, 2, 2), dtype=torch.complex64, device=DEVICE)\n",
    "\n",
    "    for f in range(n_freq):\n",
    "        w = torch.sqrt(mask_in[f])\n",
    "        Yf = Y_stft[:, f, :]\n",
    "        Yw = Yf * w\n",
    "        R_in[f] = (Yw @ Yw.conj().T) / (torch.sum(w**2) + 1e-8)\n",
    "\n",
    "    # ---------- Beamforming ----------\n",
    "    S_mvdr = torch.zeros_like(S_t)\n",
    "    S_smvb = torch.zeros_like(S_t)\n",
    "\n",
    "    for f in range(n_freq):\n",
    "        f_hz = f * FS / N_FFT\n",
    "        if f_hz < 100:\n",
    "            S_mvdr[f] = Y_stft[0, f]\n",
    "            S_smvb[f] = Y_stft[0, f]\n",
    "            continue\n",
    "\n",
    "        R = R_in[f] + SIGMA * torch.eye(2, device=DEVICE)\n",
    "        d = steering_vector(f_hz)\n",
    "\n",
    "        # MVDR\n",
    "        w_mvdr = torch.linalg.solve(R, d)\n",
    "        w_mvdr /= (d.conj().T @ w_mvdr + 1e-10)\n",
    "        S_mvdr[f] = (w_mvdr.conj().T @ Y_stft[:, f]).squeeze()\n",
    "\n",
    "        # SMVB\n",
    "        eigvals, eigvecs = torch.linalg.eigh(R_in[f])\n",
    "        v_int = eigvecs[:, -1].reshape(2, 1)\n",
    "        v_tgt = d\n",
    "        Cmat = torch.cat([v_tgt, v_int], dim=1)\n",
    "\n",
    "        if torch.linalg.cond(Cmat) < 10:\n",
    "            w_smvb = torch.linalg.solve(Cmat.conj().T,\n",
    "                                        torch.tensor([[1.0], [0.0]], device=DEVICE))\n",
    "        else:\n",
    "            w_smvb = v_tgt / 2.0\n",
    "\n",
    "        S_smvb[f] = (w_smvb.conj().T @ Y_stft[:, f]).squeeze()\n",
    "\n",
    "    # ---------- Post-filter + ISTFT ----------\n",
    "    s_mvdr = torch.istft(S_mvdr * mask_t, N_FFT, N_HOP).cpu().numpy()\n",
    "    s_smvb = torch.istft(S_smvb * mask_t, N_FFT, N_HOP).cpu().numpy()\n",
    "\n",
    "    s_mvdr /= np.max(np.abs(s_mvdr)) + 1e-10\n",
    "    s_smvb /= np.max(np.abs(s_smvb)) + 1e-10\n",
    "\n",
    "    sf.write(f\"{SAVE_DIR}/output_unified_mvdr.wav\", s_mvdr.astype(np.float32), FS)\n",
    "    sf.write(f\"{SAVE_DIR}/output_unified_smvb.wav\", s_smvb.astype(np.float32), FS)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN BULK LOOP\n",
    "# ============================================================\n",
    "def main():\n",
    "    with open(CSV_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"sample_id\", \"mvdr_sir\", \"smvb_sir\",\n",
    "                          \"mvdr_pesq\", \"smvb_pesq\"])\n",
    "\n",
    "        for i in range(N_SAMPLES):\n",
    "            print(f\"\\n=== Sample {i} ===\")\n",
    "\n",
    "            # 1. World generation\n",
    "            subprocess.run([\n",
    "                \"python\", \"world.py\",\n",
    "                \"--no-reverb\",\n",
    "                \"--dataset\", \"ljspeech\",\n",
    "                \"--n\", \"1\"\n",
    "            ], check=True)\n",
    "\n",
    "            # 2. GPU processing\n",
    "            run_beamformers_gpu()\n",
    "\n",
    "            # 3. Evaluation (MVDR)\n",
    "            s_est, s_tgt, s_int, _, _ = load_and_align_signals(\n",
    "                f\"{SAVE_DIR}/output_unified_mvdr.wav\", SAVE_DIR)\n",
    "            _, mvdr_sir, _, _, _ = calculate_osnr_and_osir(s_est, s_tgt, s_int)\n",
    "            mvdr_pesq, _ = calculate_pesq_metric(s_tgt, s_est, FS)\n",
    "\n",
    "            # 4. Evaluation (SMVB)\n",
    "            s_est, s_tgt, s_int, _, _ = load_and_align_signals(\n",
    "                f\"{SAVE_DIR}/output_unified_smvb.wav\", SAVE_DIR)\n",
    "            _, smvb_sir, _, _, _ = calculate_osnr_and_osir(s_est, s_tgt, s_int)\n",
    "            smvb_pesq, _ = calculate_pesq_metric(s_tgt, s_est, FS)\n",
    "\n",
    "            # 5. Log\n",
    "            writer.writerow([i, mvdr_sir, smvb_sir, mvdr_pesq, smvb_pesq])\n",
    "            print(f\"Logged sample {i}\")\n",
    "\n",
    "    print(\"\\nBulk comparison complete.\")\n",
    "    print(f\"Results saved to {CSV_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
